{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MHA Attention Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformer.attention import MultiHeadAttentionSlow, MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_slow = MultiHeadAttentionSlow(4096, 64)\n",
    "mha_fast = MultiHeadAttention(4096, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:24<00:00, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 54s\n",
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in tqdm(range(1000)):\n",
    "    src = torch.rand((16, 4, 4096))\n",
    "    tgt = torch.rand((16, 8, 4096))\n",
    "\n",
    "    mha_slow(query=tgt, key=src, value=src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:00<00:00, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 34s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in tqdm(range(1000)):\n",
    "    src = torch.rand((16, 4, 4096))\n",
    "    tgt = torch.rand((16, 8, 4096))\n",
    "\n",
    "    mha_fast(query=tgt, key=src, value=src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\venna\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "from transformer.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 42752\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    d_model=32,\n",
    "    nhead=2,\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2,\n",
    "    d_ffn=64,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "total_params = 0\n",
    "for param in model.parameters():\n",
    "    total_params += param.numel()\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.rand((4, 4, 32))\n",
    "tgt = torch.rand((4, 8, 32))\n",
    "tgt_mask = model.generate_square_subsequent_mask(8)\n",
    "\n",
    "outputs = model(src, tgt, tgt_mask=tgt_mask)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\venna\\Documents\\Repos\\translated-transformer\\transformer\\attention.py:130: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  d_key = torch.tensor(key.size(3))\n",
      "c:\\Users\\venna\\Documents\\Repos\\translated-transformer\\transformer\\attention.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d_key = torch.tensor(key.size(3))\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    model,\n",
    "    (src, tgt),\n",
    "    \"assets/transformer.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['src', 'tgt', 'tgt_mask'],\n",
    "    output_names=['outputs'],\n",
    "    dynamic_axes={\n",
    "        'src': {0: 'batch_size'},\n",
    "        'tgt': {0: 'batch_size'},\n",
    "        'tgt_mask': {0: 'batch_size'},\n",
    "        'outputs': {0: 'batch_size'}\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
